<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Accord.MachineLearning.GPL</name>
    </assembly>
    <members>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm for Regression
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class incorporates modifications in the original SMO algorithm to solve
              regression problems as suggested by Alex J. Smola and Bernhard Scholkopf and
              further modifications for better performance by Shevade et al.</para> 
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                 A. J. Smola and B. Scholkopf. A Tutorial on Support Vector Regression. NeuroCOLT2
                 Technical Report Series, 1998. Available on: <a href="http://www.kernel-machines.org/publications/SmoSch98c">
                 http://www.kernel-machines.org/publications/SmoSch98c </a></description></item>
                <item><description>
                 S.K. Shevade et al. Improvements to SMO Algorithm for SVM Regression, 1999. Available
                 on: <a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz">
                 http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz </a></description></item>
                <item><description>
                 G. W. Flake, S. Lawrence. Efficient SVM Regression Training with SMO.
                 Available on: <a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf">
                 http://www.keerthis.com/smoreg_ieee_shevade_00.pdf </a></description></item>
              </list></para>
            </remarks>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.#ctor(Accord.MachineLearning.VectorMachines.SupportVectorMachine,System.Double[][],System.Double[])">
            <summary>
              Initializes a new instance of a Sequential Minimal Optimization (SMO) algorithm.
            </summary>
            
            <param name="machine">A Support Vector Machine.</param>
            <param name="inputs">The input data points as row vectors.</param>
            <param name="outputs">The classification label for each data point.</param>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Run(System.Boolean)">
            <summary>
              Runs the SMO algorithm.
            </summary>
            
            <param name="computeError">
              True to compute error after the training
              process completes, false otherwise. Default is true.
            </param>
            
            <returns>
              The sum of squares error rate for
              the resulting support vector machine.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Run">
            <summary>
              Runs the SMO algorithm.
            </summary>
            
            <returns>
              The sum of squares error rate for
              the resulting support vector machine.
            </returns>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.ComputeError(System.Double[][],System.Double[])">
            <summary>
              Computes the error ratio for a given set of input and outputs.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.examineExample(System.Int32)">
            <summary>
             Chooses which multipliers to optimize using heuristics.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.takeStep(System.Int32,System.Int32)">
            <summary>
              Analytically solves the optimization problem for two Lagrange multipliers.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.compute(System.Double[])">
            <summary>
              Computes the SVM output for a given point.
            </summary>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Complexity">
            <summary>
              Complexity (cost) parameter C. Increasing the value of C forces the creation
              of a more accurate model that may not generalize well. Default value is 1.
            </summary>
            
            <remarks>
              The cost parameter C controls the trade off between allowing training
              errors and forcing rigid margins. It creates a soft margin that permits
              some misclassifications. Increasing the value of C increases the cost of
              misclassifying points and forces the creation of a more accurate model
              that may not generalize well.
            </remarks>
            
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Epsilon">
            <summary>
              Insensitivity zone ε. Increasing the value of ε can result in fewer support
              vectors in the created model. Default value is 1e-3.
            </summary>
            <remarks>
              Parameter ε controls the width of the ε-insensitive zone, used to fit the training
              data. The value of ε can affect the number of support vectors used to construct the
              regression function. The bigger ε, the fewer support vectors are selected. On the
              other hand, bigger ε-values results in more flat estimates.
            </remarks>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-3.
            </summary>
            <remarks>
              The criterion for completing the model training process. The default is 0.001.
            </remarks>
        </member>
    </members>
</doc>
